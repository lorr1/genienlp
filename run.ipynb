{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First download genienlp and checkout the master branch (skip this step if you're running this notebook within genienlp already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/stanford-oval/genienlp.git genienlp; \\\n",
    "    cd genienlp ; \\\n",
    "    git checkout 096af96e3f61e7a3a0ffba630607463105e28eee ; \\\n",
    "    pip3 install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now copy over your dataset to `datadir/almond/` folder. It should have at least train.tsv and eval.tsv files. If you want to predict on test set, you should include test.tsv file as well.\n",
    "- Depending on the task the format of your data should be different. For a sample of data for almond task (semantic parsing) please checkout `tests/dataset/almond/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your dataset in datadir/almond/\n",
    "!mkdir -p datadir/almond/\n",
    "!cp -r tests/dataset/almond/ datadir/almond/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Follow instructions here https://github.com/HazyResearch/bootleg/tree/7ab94e794963409f5fe905becdd006c1588ababc\n",
    "and run `download_bert.sh`, `download_model.sh`, and `download_wiki.sh`.\n",
    "- Extract all the files into `database` directory\n",
    "- Run the following command which will generate bootleg_label files in `results_temp` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!genienlp bootleg-dump-features --train_tasks almond --save workdir/ --preserve_case --data datadir/  --database_type json --database_dir tests/database/ --ned_features type_id type_prob --ned_features_size 1 1 --ned_features_default_val 0 1.0 --num_workers 0 --min_entity_len 1 --max_entity_len 4 --bootleg_model bootleg_wiki_types --exist_ok\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now you can use the extracted features from bootleg in downstream tasks such as semantic parsing\n",
    "- Run following to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!genienlp train --train_tasks almond --train_iterations 60 --preserve_case --save workdir/ --data datadir/ --model TransformerSeq2Seq --pretrained_model facebook/bart-base --trainable_decoder_embeddings 50 --train_batch_tokens 1000 --val_batch_size 1000 --do_ned --database_type json --database_dir tests/database/ --ned_retrieve_method bootleg --ned_features type_id type_prob --ned_features_size 1 1 --ned_features_default_val 0 1.0 --num_workers 0 --min_entity_len 1 --max_entity_len 4 --bootleg_model bootleg_wiki_types --exist_ok --add_types_to_text append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After training is done, you can evaluate the model using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!genienlp predict --tasks almond --data datadir/ --path workdir/ --eval_dir eval_dir/ --evaluate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
